general:
    device: cuda
    seed: 42
    output_root: ./output
    data_name:

model:
    network:
        unet:
            image_size: 64
            in_channels: 3
            out_channels: 3
            model_channels: 64
            emb_channels: 512
            channel_multipliers: [1, 2, 4, 8]
            num_resnet_blocks: 2
            resnet_dropout: 0.1
            attn_resolution: [16, ]
            use_conv_resample: True
            num_groups: 32
        encoder:
            image_size: 64
            in_channels: 3
            out_channels: 3
            model_channels: 64
            emb_channels: 512
            channel_multipliers: [1, 2, 4, 8, 8]
            num_resnet_blocks: 2
            resnet_dropout: 0.1
            attn_resolution: [16, ]
            use_conv_resample: True
            num_groups: 32
    timesteps:
        num: 1000
        sample: uniform
    beta:
        schedule: linear
        linear:
            start: 0.0001
            end: 0.02
        cosine:
            s: 0.008
            max_beta: 0.999

train:
    epoch: 500
    fp16: True
    grad_accum_steps: 1
    log_interval: 100
    dataset:
        - name: Resize
          params:
              size: [64, 64]
        - name: RandomHorizontalFlip
          params:
              p: 0.5
        - name: ToTensor
          params: {}
        - name: Normalize
          params:
              mean: [0.5, 0.5, 0.5]
              std: [0.5, 0.5, 0.5]
    dataloader:
        batch_size: 128
        shuffle: True
        num_workers: 4
        pin_memory: True
        drop_last: True
    loss:
        name: SimpleLoss
    optimizer:
        name: Adam
        params:
            lr: 0.0001
            weight_decay: 0

test:
    dataset:
        - name: Resize
          params:
              size: [64, 64]
        - name: ToTensor
          params: {}
        - name: Normalize
          params:
              mean: [0.5, 0.5, 0.5]
              std: [0.5, 0.5, 0.5]
    dataloader:
        batch_size: 128
        shuffle: False
        num_workers: 4
        pin_memory: True
        drop_last: False

classifier:
    num_class: 40
    train:
        epoch: 100
        fp16: True
        grad_accum_steps: 1
        log_interval: 500
        dataloader:
            batch_size: 128
            shuffle: True
            num_workers: 1
            pin_memory: False
            drop_last: True
        loss:
            name: BCEWithLogitsLoss
        optimizer:
            name: Adam
            params:
                lr: 0.001
                weight_decay: 0
